{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import random\n",
    "\n",
    "@jit(nopython=True)\n",
    "def monte_carlo_pi(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x ** 2 + y ** 2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141916"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "monte_carlo_pi(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.63200664  0.35868749 -0.88308861  0.85521855  0.40723921 -0.41009166\n",
      " -0.04985493  0.0773229   1.69922401  0.79534132]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "14.17832064628601\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda, float32\n",
    "import time\n",
    "import math\n",
    "@cuda.jit\n",
    "def increment_by_one(an_array):\n",
    "    # Thread id in a 1D block\n",
    "    tx = cuda.threadIdx.x\n",
    "    # Block id in a 1D grid\n",
    "    ty = cuda.blockIdx.x\n",
    "    # Block width, i.e. number of threads per block\n",
    "    bw = cuda.blockDim.x\n",
    "    # Compute flattened index inside the array\n",
    "    pos = tx + ty * bw\n",
    "    for i in range(1000000):\n",
    "        if pos < an_array.size:  # Check array boundaries\n",
    "            an_array[pos] = math.sqrt(abs(an_array[pos]))\n",
    "\n",
    "an_array = np.random.normal(0,1,size=2**15)\n",
    "print(an_array[:10])\n",
    "threadsperblock = 64\n",
    "blockspergrid = (an_array.size + (threadsperblock - 1)) // threadsperblock\n",
    "t1 = time.time()\n",
    "increment_by_one[blockspergrid, threadsperblock](an_array)\n",
    "t2 = time.time()\n",
    "print(an_array[:10])\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.22390604019165\n"
     ]
    }
   ],
   "source": [
    "@jit(nopython=True)\n",
    "def inc(an_array):\n",
    "    for i in range(1000000):\n",
    "        an_array = np.sqrt(np.abs(an_array))\n",
    "    return an_array\n",
    "\n",
    "t1 = time.time()\n",
    "an_array = inc(np.random.normal(0,1,size=2**15))\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.132588863372803\n"
     ]
    }
   ],
   "source": [
    "an_array = np.random.normal(0,1,size=2**15)\n",
    "t1 = time.time()\n",
    "an_array = inc(an_array)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plt.scatter(x[:,0],x[:,1],alpha=0.02)\n",
    "\n",
    "@cuda.jit\n",
    "def mcmc(data):\n",
    "    shared = cuda.shared.array(shape=(2**11, 2), dtype=float32)\n",
    "    tx = cuda.threadIdx.x  # Thread ID\n",
    "    ty = cuda.blockIdx.x  # Block ID\n",
    "    bw = cuda.blockDim.x  # Block Size\n",
    "    idx = bw*ty+tx\n",
    "    \n",
    "    theta = (0,0)\n",
    "    x = data[idx]\n",
    "    log_p = -(((theta[0]-x[0])**2)/(2*0.1) + ((theta[1]-x[1])**2)/(2*0.1))\n",
    "    shared[tx] = log_p\n",
    "    \n",
    "    s = bw//2\n",
    "    while s>0:\n",
    "        if tx < s:\n",
    "            shared[tx,0] += shared[tx+s,0]\n",
    "            shared[tx,1] += shared[tx+s,1]\n",
    "        cuda.syncthreads()\n",
    "        s>>=1\n",
    "    \n",
    "    \n",
    "#     for (unsigned int s=blockDim.x/2; s>0; s>>=1) {\n",
    "#     if (tid < s) {\n",
    "#     sdata[tid] += sdata[tid + s];\n",
    "#     }\n",
    "#     __syncthreads();\n",
    "#     }\n",
    "\n",
    "\n",
    "# Prior distribution\n",
    "theta_0 =  np.random.multivariate_normal([1,1],cov=[[1, 0.5],[0.5, 1]])\n",
    "data = np.random.multivariate_normal(theta_0,cov=[[0.1, 0],[0, 0.1]],size=2**5)\n",
    "threadsperblock = 32\n",
    "blockspergrid = (data.size + (threadsperblock - 1)) // threadsperblock\n",
    "mcmc[blockspergrid, threadsperblock](data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09435389770895924"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal as mn\n",
    "mn.pdf([0,0],mean=[1,1],cov=[[1, 0.5],[0.5, 1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
